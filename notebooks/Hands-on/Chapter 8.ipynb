{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data[:, 0:4]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis = 1).reshape(-1, 1)# Before you perform SVD, you need to center the data first\n",
    "U, s, Vt = np.linalg.svd(X_centered) # Use svd() to perform Singular Value Decomposition\n",
    "c1 = Vt.T[:, 0] # Obtain the first unit vector(the first axis)\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting Down to d Dimensions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reduce the dimensionality of the dataset down to d dimensions by projecting it onto the hyperplane defined by the first d principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the training set down to d dimensions\n",
    "$$X_{d-proj}=XW_{d}$$\n",
    "<br>Where $W_{d}$ is the first d columns of $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2) #projects the training set onto the plane defined by the first 2 PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92461872, 0.05306648])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress first, then reconstruct datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X) #先降维\n",
    "X_recovered = pca.inverse_transform(X_reduced)#再根据reduced的dataset reconstruct回去\n",
    "#reconstruct的dataset不是和之前的一模一样的，但是可以说非常close to original dataset了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly find the approximation of first d principal components\n",
    "#速度比不random的快很多很多，但是得到的是approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=2, svd_solver='randomized')\n",
    "X_reduced = rnd_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不是一次把所有data给PCA，而是分成batch一点一点给IPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=2)\n",
    "for X_batch in np.array_split(X, n_batches):\n",
    "    inc_pca.partial_fit(X_batch) #注意这里使用的是partial fit instead of fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components=2, kernel = 'rbf', gamma = 0.04) #和SVC一样，你可以set自己想要的kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Kernel and Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps = [\n",
    "    ('kpca', KernelPCA(n_components=2)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "param_grid = [{'kpca__gamma': np.linspace(0.03, 0.05, 10), 'kpca__kernel': ['rbf', 'sigmoid']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('kpca', KernelPCA(n_components=2)),\n",
       "                                       ('log_reg', LogisticRegression())]),\n",
       "             param_grid=[{'kpca__gamma': array([0.03      , 0.03222222, 0.03444444, 0.03666667, 0.03888889,\n",
       "       0.04111111, 0.04333333, 0.04555556, 0.04777778, 0.05      ]),\n",
       "                          'kpca__kernel': ['rbf', 'sigmoid']}])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv = 3)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kpca__gamma': 0.03, 'kpca__kernel': 'rbf'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally Linear Embedding (LLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This approach is particularly good at unrolling twisted manifolds, especially when there is not too much noise"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does LLE works?\n",
    "<br>\n",
    "1. Find *k* closets neighbors for each training instance x\n",
    "2. Try to reconstruct x as a linear function of these neighbors, such that the squared distance between x and these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
